points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
plot(training$age,training$wage,pch=19,cex=0.5)
plot(training$age,training$wage,pch=19)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",type="l")
points(training$age,predict(lm1,newdata=training),col="red")
plot(training$age,training$wage,pch=19)
points(training$age,predict(lm1,newdata=training),col="red")
points(training$age,predict(lm1,newdata=training),col="red", pch=19)
predict(bsBasis,age=testing$age)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
plot(spam[,34],spam[,32])
X <- 0.71*training$num415 + 0.71*training$num857
Y <- 0.71*training$num415 - 0.71*training$num857
plot(X,Y)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
names(prcomp)
names(prComp)
class(prComp$x)
dim(prComp$x)
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
?preProcess
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
rm(list=ls())
require(caret);data(faithful); set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,
p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")plot()
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lm1 <- lm(eruptions ~ waiting,data=trainFaith)
summary(lm1)
abline(lm1)
abline(lm1, col=2, lwd=2)
predict(lm1, newdata=data.frame(waiting=80))
coef(lm1)[1] + coef(lm1)[2] * 80
par(mfrow=c(1,2))
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,predict(lm1),lwd=3)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
abline(lm1,col=2,lwd=2)
# Calculate RMSE on training
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
par(mfrow=c(1,1))
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
?matlines
modFit <- train(eruptions ~ waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
modFit$resample
rm(list=ls())
?train
require(ISLR); require(ggplot2); require(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
modFit<- train(wage ~ age + jobclass + education,
method = "lm",data=training)
finMod <- modFit$finalModel
print(modFit)
print(finMod)
summary(finMod)
finMod$coef
coef(finMod)
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
plot(finMod)
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
plot(finMod$residuals)
plot(finMod$residuals, pch=19)
# Plot predicted values vs truth in test set
pred <- predict(modFit, testing)
qplot(wage,pred,colour=year,data=testing)
p1 <- qplot(wage,pred,colour=year,data=testing)
p1
pred <- predict(modFit,training)
p2 <- qplot(wage,pred,colour=year,data=training)
p2
grid.arrange(p1,p2)
require(gridExtra)
grid.arrange(p1,p2,ncol=2)
p2 <- qplot(wage,pred,colour=year,data=training)
p2
pred <- predict(modFit, testing)
p1 <- qplot(wage,pred,colour=year,data=testing)
p1
grid.arrange(p1,p2,ncol=2)
pred1 <- predict(modFit, testing)
p1 <- qplot(wage,pred1,colour=year,data=testing)
p1
pred2 <- predict(modFit,training)
p2 <- qplot(wage,pred2,colour=year,data=training)
p2
require(gridExtra)
# grid.arrange(p1,p2,ncol=2)
grid.arrange(p1,p2,ncol=2)
modFitAll<- train(wage ~ .,data=training,method="lm")
pred <- predict(modFitAll, testing)
qplot(wage,pred,data=testing)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
fitControl$method
?trainControl
modFitAll$method
modFitAll$finalModel
summary(modFitAll$finalModel)
modFitAll<- train(wage ~ .,data=training,method="lm")
summary(modFitAll$finalModel)
modFitAll$resample
rm(list=ls())
# Get IBM and Linkedin stock data from Yahoo Finance
ibm_url <- "http://real-chart.finance.yahoo.com/table.csv?s=IBM&a=07&b=24&c=2010&d=07&e=24&f=2015&g=d&ignore=.csv"
lnkd_url <- "http://real-chart.finance.yahoo.com/table.csv?s=LNKD&a=07&b=24&c=2010&d=07&e=24&f=2015&g=d&ignore=.csv"
yahoo.read <- function(url){
dat <- read.table(url,header=TRUE,sep=",")
df <- dat[,c(1,5)]
df$Date <- as.Date(as.character(df$Date))
return(df)}
ibm  <- yahoo.read(ibm_url)
lnkd2 <- yahoo.read(lnkd_url)
theme(plot.title = element_text(lineheight=.7, face="bold"))
ggplot(ibm,aes(Date,Close)) +
geom_line(aes(color="ibm")) +
geom_line(data=lnkd,aes(color="lnkd")) +
labs(color="Legend") +
scale_colour_manual("", breaks = c("ibm", "lnkd"),
values = c("blue", "brown")) +
ggtitle("Closing Stock Prices: IBM & Linkedin") +
theme(plot.title = element_text(lineheight=.7, face="bold"))
View(ibm)
ggplot(ibm,aes(Date,Close)) +
geom_line(aes(color="ibm")) +
geom_line(data=lnkd2,aes(color="lnkd")) +
labs(color="Legend") +
scale_colour_manual("", breaks = c("ibm", "lnkd"),
values = c("blue", "brown")) +
ggtitle("Closing Stock Prices: IBM & Linkedin") +
theme(plot.title = element_text(lineheight=.7, face="bold"))
install.packages("xts")
install.packages("dygraphs")
library(xts)
library(dygraphs)
ibm_xts <- xts(ibm$Close,order.by=ibm$Date,frequency=365)
lnkd_xts <- xts(lnkd$Close,order.by=lnkd$Date,frequency=365)
lnkd_xts <- xts(lnkd2$Close,order.by=lnkd$Date,frequency=365)
lnkd_xts <- xts(lnkd2$Close,order.by=lnkd2$Date,frequency=365)
stocks <- cbind(ibm_xts,lnkd_xts)
View(stocks)
dygraph(stocks,ylab="Close",
main="IBM and Linkedin Closing Stock Prices") %>%
dySeries("..1",label="IBM") %>%
dySeries("..2",label="LNKD") %>%
dyOptions(colors = c("blue","brown")) %>%
dyRangeSelector()
ggplot(ibm,aes(Date,Close)) +
geom_line(aes(color="ibm")) +
geom_line(data=lnkd2,aes(color="lnkd")) +
labs(color="Legend") +
scale_colour_manual("", breaks = c("ibm", "lnkd"),
values = c("blue", "brown")) +
ggtitle("Closing Stock Prices: IBM & Linkedin") +
theme(plot.title = element_text(lineheight=.7, face="bold"))
windows()
dygraph(stocks,ylab="Close",
main="IBM and Linkedin Closing Stock Prices") %>%
dySeries("..1",label="IBM") %>%
dySeries("..2",label="LNKD") %>%
dyOptions(colors = c("blue","brown")) %>%
dyRangeSelector()
ggplot(ibm,aes(Date,Close)) +
geom_line(aes(color="ibm")) +
geom_line(data=lnkd2,aes(color="lnkd")) +
labs(color="Legend") +
scale_colour_manual("", breaks = c("ibm", "lnkd"),
values = c("blue", "brown")) +
ggtitle("Closing Stock Prices: IBM & Linkedin") +
theme(plot.title = element_text(lineheight=.7, face="bold"))
ggplot(ibm,aes(Date,Close)) +
geom_line(aes(color="ibm")) +
geom_line(data=lnkd2,aes(color="lnkd")) +
labs(color="Legend") +
scale_colour_manual("", breaks = c("ibm", "lnkd"),
values = c("blue", "brown")) +
ggtitle("Closing Stock Prices: IBM & Linkedin") +
theme(plot.title = element_text(lineheight=.7, face="bold"))
dygraph(stocks,ylab="Close",
main="IBM and Linkedin Closing Stock Prices") %>%
dySeries("..1",label="IBM") %>%
dySeries("..2",label="LNKD") %>%
dyOptions(colors = c("blue","brown")) %>%
dyRangeSelector()
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
require(dplyr)
library(pgmm)
data(olive)
olive = olive[,-1]
nd <- as.data.frame(t(colMeans(olive)))
myTree <- rpart(Area~., data=olive)
predict(myTree, newdata=nd)
library(pgmm)
data(olive)
olive = olive[,-1]
nd <- as.data.frame(t(colMeans(olive)))
myTree <- rpart(Area~., data=olive)
predict(myTree, newdata=nd)
require(rpart)
myTree <- rpart(Area~., data=olive)
predict(myTree, newdata=nd)
?tree
names(getModelInfo())
?ctree
?ct
?dt
?dtree
rm(list=ls())
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
?SAheart
fitMod <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA,
method="glm", family="binomial")
table(trainSA$chd)
str(SAheart)
trainSA$chd <- factor(trainSA$chd, labels=c("No", "Yes"))
source('~/.active-rstudio-document', echo=TRUE)
rm(list=ls())
# q4
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
trainSA$chd <- factor(trainSA$chd, labels=c("No", "Yes"))
table(trainSA$chd)
View(trainSA)
fitMod <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA,
method="glm", family="binomial")
missClass = function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)}
misTest <- missClass(trainSA$chd, predict(fitMod, trainSA))
?predict
misTest <- missClass(trainSA$chd, predict(fitMod, trainSA, type="response"))
?predict.train
misTest <- missClass(trainSA$chd, predict(fitMod, trainSA, type="prob"))
misTrain <- missClass(trainSA$chd, predict(fitMod, trainSA, type="prob"))
misTest <- missClass(testSA$chd, predict(fitMod, trainSA, type="prob"))
rbind(misTest, misTrain)
misTrain <- missClass(trainSA$chd, predict.glm(fitMod, trainSA, type="response"))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
trainSA$chd <- factor(trainSA$chd, labels=c("No", "Yes"))
table(trainSA$chd)
fitMod <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA,
method="glm", family="binomial")
missClass = function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)}
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
trainSA$chdFactor <- factor(trainSA$chd, labels=c("No", "Yes"))
table(trainSA$chd)
fitMod <- train(chdFactor ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA,
method="glm", family="binomial")
misTrain <- missClass(trainSA$chd, predict(fitMod, trainSA, type="prob"))
misTest <- missClass(testSA$chd, predict(fitMod, trainSA, type="prob"))
rbind(misTest, misTrain)
confusionMatrix(testSA$chdFactor, predict(fitMod, testSA))
testSA$chdFactor <- factor(trainSA$chd, labels=c("No", "Yes"))
confusionMatrix(testSA$chdFactor, predict(fitMod, testSA))
confusionMatrix(trainSA$chdFactor, predict(fitMod, trainSA))
hist(predict(fitMod, testSA, type="prob"))
predict(fitMod, testSA, type="prob")
misTrain <- missClass(trainSA$chd, predict(fitMod, trainSA, type="prob")[,2])
misTest <- missClass(testSA$chd, predict(fitMod, trainSA, type="prob")[,2])
rbind(misTest, misTrain)
rm(list=ls())
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
trainSA$chdFactor <- factor(trainSA$chd, labels=c("No", "Yes"))
testSA$chdFactor <- factor(trainSA$chd, labels=c("No", "Yes"))
table(trainSA$chd)
fitMod <- train(chdFactor ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA,
method="glm", family="binomial")
missClass = function(values,prediction){
sum(((prediction > 0.5)*1) != values)/length(values)}
misTrain <- missClass(trainSA$chd, predict(fitMod, trainSA, type="prob")[,2])
misTest <- missClass(testSA$chd, predict(fitMod, trainSA, type="prob")[,2])
rbind(misTest, misTrain)
?glm
?lm
?glm
fitMod2 <- glm(chdFactor ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA,
family="binomial")
predict(fitMod2, trainSA, type="response")
misTrain <- missClass(trainSA$chd, predict(fitMod2, trainSA, type="response"))
misTest <- missClass(testSA$chd, predict(fitMod, trainSA, type="response"))
misTest <- missClass(testSA$chd, predict(fitMod2, trainSA, type="response"))
rbind(misTest, misTrain)
rm(list=ls())
install.packages("tree")
?tree
require(tree)
?tree
require(tree)
rm(list=ls())
library(pgmm)
data(olive)
olive = olive[,-1]
nd <- as.data.frame(t(colMeans(olive)))
require(rpart)
myTree <- rpart(Area~., data=olive)
predict(myTree, newdata=nd)
require(tree)
myTree2 <- tree(Area~., data=olive)
predict(myTree2, newdata=nd)
plot(myTree2)
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
table(vowel.train$y)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
fitMod <- train(y~., data=vowel.train, method="rf")
?varImp
varImp(fitMod)
?product
?sample
a <- c(.99,1.01,1.01)
b <- sample(a, 100, replace=T)
product <- function(x){pr=x[1];for(i in 2:length(x)){pr=pr*x[i]};pr}
product(c(2,3))
product(b)
b <- sample(a, 200, replace=T)
product(b)
x <- 1:200
y <- rep(1,200)
for(i in 2:200){y[i]=y[i-1]*sample(a,1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(a,1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(a,1)}
plot(x,y, type="l")
par(mar=c(1,1,1,1))
plot(x,y, type="l")
par(mar=c(2,2,1,1))
plot(x,y, type="l")
par(mar=c(2,2,1,1)+.2)
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,.99,1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,.99,1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,.99,1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.98,1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.98,1.02, 1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.98,1.02, 1.02),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.98,1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.98,1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,1.015),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99,1.015),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99, .99, 1.01, 1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99, .99, 1.01, 1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99, .99, 1.01, 1.01, 1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99, .99, .99, 1.01, 1.01, 1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99, .99, .99, 1.01, 1.01, 1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(.99, .99, .99, 1.01, 1.01, 1.01, 1.01, 1.01),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,2), rep(1.01,4)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,2), rep(1.01,4)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,9)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,9)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,6)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,6)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,6)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,7)),1)}
plot(x,y, type="l")
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,7)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,7)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,10)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,10)),1)}
plot(x,y, type="l")
for(i in 2:200){y[i]=y[i-1]*sample(c(rep(.99,5), rep(1.01,10)),1)}
plot(x,y, type="l")
## q1
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50, list=F)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
devtools::install_github('rstudio/shinyapps')
install.packages("Rtools")
require(ggplot2)
install.packages("devtools")
devtools::install_github('rstudio/shinyapps')
traceback()
library(shinyapps)
shiny::runApp('coursera/DataProducts/DataproductsCourseProject')
shiny::runApp('coursera/DataProducts/DataproductsCourseProject')
setwd("C:/temp/ra/_doku/coursera/DataProducts/slidify")
setwd("C:/temp/ra/_doku/coursera/DataProducts/DataproductsCourseProject")
library(slidify)
install.packages("devtools")
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
setwd("C:/temp/ra/_doku/coursera/DataProducts/slidify/egy_prezi")
setwd("C:/temp/ra/_doku/coursera/DataProducts/DataproductsCourseProject")
author("DataProductsCourseProject")
